{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nWJaQdVdaVET"
      },
      "source": [
        "## Basic Visualizations\n",
        "Performing some basic statistics on the dataset to get a better understanding of it. The results are on the preprocessed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmfN56t3QfIm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-TddOQrW4my"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"../data/assignment_preprocessed.csv\")\n",
        "columns = dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdzBcgMgXqJ7"
      },
      "outputs": [],
      "source": [
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qY0pK2zY-fJ",
        "outputId": "cd3a442e-3e32-41cd-f8c9-a76a9967c139"
      },
      "outputs": [],
      "source": [
        "print('Shape of Dataset:', dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX2ExXbgZBKY"
      },
      "outputs": [],
      "source": [
        "dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGuZ9ZRjZMAN",
        "outputId": "f32af69e-ad99-4dc3-e0a6-35cf2e479282"
      },
      "outputs": [],
      "source": [
        "# check how many entries are empty in a specific column\n",
        "dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bynH519BZUhq",
        "outputId": "889539f5-3b1c-408b-c3ea-2dc3b1a863ef"
      },
      "outputs": [],
      "source": [
        "# count the number of duplicate entries while excluding the unique id and the agent_id\n",
        "dataset[dataset.columns.difference(['id', 'agent_id'])].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oaZenYF5YI1J",
        "outputId": "4d82498b-b92b-4a88-dd61-96fdb8bf94fa"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_yCudaJb2cI",
        "outputId": "16273c08-935c-447c-cee0-6d480eda0495"
      },
      "outputs": [],
      "source": [
        "# get number of unique values per column\n",
        "dataset.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A2xDhQ76jYJ"
      },
      "outputs": [],
      "source": [
        "# print(dataset.isnull().sum())\n",
        "null_percentage = dataset.isnull().sum() / len(dataset) * 100\n",
        "# create a list of columns with more than 80% null values\n",
        "columns_to_drop = null_percentage[null_percentage > 80].index.tolist()\n",
        "# drop the columns with more than 80% null values\n",
        "dataset.drop(columns_to_drop, axis=1, inplace=True)\n",
        "# drop rows where data is missing from specific columns\n",
        "dataset.dropna(subset=columns[0:10].append(columns[13:18]), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuNJtmRsGbJD",
        "outputId": "dcdbbafb-7a64-4c6b-d76e-a5a9d22bdfaa"
      },
      "outputs": [],
      "source": [
        "dataset.iloc[7378]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rYDgAmE2AOs1",
        "outputId": "74624989-5448-4e5f-a9f5-719630181c80"
      },
      "outputs": [],
      "source": [
        "dataset[dataset.columns.difference(['id', 'agent_id', 'ranking_score'])].select_dtypes(include=np.number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XdNnfAjaG9WA",
        "outputId": "469e40c1-7249-4346-e69b-b5e65eed5c84"
      },
      "outputs": [],
      "source": [
        "dataset.select_dtypes(include=np.number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "reZy1juUHwAH",
        "outputId": "64e439ca-870d-49a1-b837-1c4f3039b9da"
      },
      "outputs": [],
      "source": [
        "dataset.drop([262])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2I2Lm0Ky-8kg",
        "outputId": "9a3583ee-67d5-46ce-e3e1-63a323a9c358"
      },
      "outputs": [],
      "source": [
        "# define a threshold for z-score\n",
        "threshold = 3\n",
        "\n",
        "# loop through each numeric column\n",
        "for col in dataset.select_dtypes(include=np.number):\n",
        "    print(col)\n",
        "    # calculate z-score for each value in the column\n",
        "    z = np.abs(stats.zscore(dataset[col]))\n",
        "    # identify outliers based on the threshold\n",
        "    outliers = list(np.where(z > threshold))\n",
        "    # drop rows containing outliers\n",
        "    dataset.drop(outliers[0], axis=0, inplace=True)\n",
        "\n",
        "# save the cleaned dataset\n",
        "# dataset.to_csv('cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGoYprvF_eFj"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tYsuCYlXoT7"
      },
      "outputs": [],
      "source": [
        "dataset['subtype'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "wunGF-5Wa9Wi",
        "outputId": "5d1d3944-f88e-4b64-e67a-950a1a85a2fe"
      },
      "outputs": [],
      "source": [
        "# bar chart of counts for subtypes of houses\n",
        "ax = dataset['subtype'].value_counts().plot.barh(figsize=(8, 8))\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.xlabel(\"Count\", labelpad=12)\n",
        "plt.ylabel(\"Subtypes\", labelpad=12)\n",
        "plt.title(\"Count of Listings of each Subtype\", y=1.02);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "bcxLUEaUgrXL",
        "outputId": "840453b3-0565-4734-a3d3-e071afd3f7b0"
      },
      "outputs": [],
      "source": [
        "# bar chart of counts for subtypes of houses\n",
        "ax = dataset['geography_name'].value_counts().plot.barh(figsize=(8, 8))\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.xlabel(\"Count\", labelpad=12)\n",
        "plt.ylabel(\"Area in Athens\", labelpad=12)\n",
        "plt.title(\"Count of Listings in each Area of Athens\", y=1.02);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt9OMi9ojINx"
      },
      "outputs": [],
      "source": [
        "# create a new column with decade information\n",
        "decade = pd.cut(dataset['year_of_construction'], bins=range(int(dataset['year_of_construction'].min()), int(dataset['year_of_construction'].max()), 10), labels=[f\"{i}s\" for i in range(int(dataset['year_of_construction'].min()), 2150, 10)])\n",
        "\n",
        "# # group by decade and count the number of rows in each group\n",
        "# grouped_df = df.groupby('decade').size().reset_index(name='count')\n",
        "\n",
        "# print(grouped_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0s4a6TRdS0W"
      },
      "outputs": [],
      "source": [
        "# scatter plot for two numerical variables\n",
        "plt.scatter(df['column_name1'], df['column_name2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj4D0yRZa7rV"
      },
      "outputs": [],
      "source": [
        "# drop columns with high null values or low variance\n",
        "df.drop(['column_name1', 'column_name2'], axis=1, inplace=True)\n",
        "\n",
        "# fill null values with mean or mode\n",
        "df['column_name'].fillna(df['column_name'].mean(), inplace=True)\n",
        "\n",
        "# create dummy variables for categorical columns\n",
        "df = pd.get_dummies(df, columns=['column_name'])\n",
        "\n",
        "# scale numerical columns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df[['column_name1', 'column_name2']] = scaler.fit_transform(df[['column_name1', 'column_name2']])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
